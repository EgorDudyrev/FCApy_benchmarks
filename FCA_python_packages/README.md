# FCA python benchmarks

Currently, we compare the performance of
[FCApy](https://github.com/xflr6/concepts) and [Concepts](https://github.com/xflr6/concepts) packages.

## Results

### Time to construct a lattice

Classic FCA contexts
![Lattice Construction Classic](https://github.com/EgorDudyrev/FCApy_benchmarks/blob/main/FCA_python_packages/imgs/lattice_construction_time/classic_contexts.png?raw=true)

Randomly generated contexts
![Lattice Construction Random](https://github.com/EgorDudyrev/FCApy_benchmarks/blob/main/FCA_python_packages/imgs/lattice_construction_time/random_contexts.png?raw=true)

### Time to compute extents and intents

Classic and Randomly generated contexts
![Extent intent time All](https://github.com/EgorDudyrev/FCApy_benchmarks/blob/main/FCA_python_packages/imgs/intent_extent_time/all_data.png?raw=true)


### Lattice visualizations
[Directory](https://github.com/EgorDudyrev/FCApy_benchmarks/tree/main/FCA_python_packages/imgs/lattice_visualization)
with various lattice visualizations by compared packages. 

# Additional info

The script to run the benchmark is located in
[Performance_Benchmark.ipynb](https://github.com/EgorDudyrev/FCApy_benchmarks/blob/main/FCA_python_packages/Performance_Benchmark.ipynb)
notebook.
