{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import performance_benchmark as pbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "There are a number of python packages to work with FCA. In this notebook we will compare their performances in the basic FCA task: constructing the concept lattice from a formal context.\n",
    "\n",
    "We consider two packages: FCApy and Concepts\n",
    "\n",
    "// More packages can be compared in the future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install competitors libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`FCApy` package (by Egor Dudyrev, HSE Moscow): https://github.com/EgorDudyrev/FCApy "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip -q install -U fcapy[context,lattice] --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Concepts` package (by Sebastian Bank, University of Leipzig): https://github.com/xflr6/concepts"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip -q install -U concepts --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fcapsy` package (by Tomáš Mikula, Palacký University): https://github.com/mikulatomas/fcapsy\n",
    "\n",
    "Upd. We drop `fcapsy` package from the benchmark since now it uses `concepts` package under the hood"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip -q install -U fcapsy --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load some classic FCA contexts (datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts_to_test = ['animal_movement', 'digits', 'gewaesser','lattice', 'liveinwater', 'tealady']\n",
    "frames_classic = pbench.load_classic_context(contexts_to_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Bob-Ross dataset which has more objects and attributes than the classic FCA datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_classic['bob_ross'] = pbench.load_bob_ross_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These classic real world contexts are small so we add some big random contexts to our examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_objects_vars = [10, 30, 100]\n",
    "n_attributes_vars = [10, 30, 50]\n",
    "densities_vars = [0.1, 0.5, 0.9]\n",
    "\n",
    "frames_random = pbench.generate_random_contexts(n_objects_vars, n_attributes_vars, densities_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = dict(frames_classic, **frames_random)\n",
    "#frames = dict(frames_classic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default lattice visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take one classic FCA context 'animal movement' and a bigger one 'bob ross' dataset\n",
    "\n",
    "The description of Animals context:\n",
    "* objects (rows) are Animals\n",
    "* attributes (columns) are Actions\n",
    "* the table shows whether an Animal can perform an Action\n",
    "\n",
    "The description of Bob Ross dataset:\n",
    "* objects (rows) are paintings by Bob Ross\n",
    "* attributes (columns) are specific elements in these paintings\n",
    "* the table shows whether an element is on a painting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_names = ['animal_movement', 'tealady']#'bob_ross']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization by `concepts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "animal_movement\n",
      "Lattice constructed in 0.001369 seconds\n",
      "Executed in 0.043852 seconds\n",
      "tealady\n",
      "Lattice constructed in 0.006612 seconds\n",
      "Executed in 0.05267 seconds\n"
     ]
    }
   ],
   "source": [
    "pbench.visualize_by_concepts(K_names, frames, \"imgs/lattice_visualization/concepts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization by `fcapy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "animal_movement\n",
      "Lattice constructed in 0.001838 seconds\n",
      "Visualizer constructed in 0.002062 seconds\n",
      "Png saved in 0.1977 seconds\n",
      "tealady\n",
      "Lattice constructed in 0.027946 seconds\n",
      "Visualizer constructed in 0.028471 seconds\n",
      "Png saved in 0.834006 seconds\n"
     ]
    }
   ],
   "source": [
    "pbench.visualize_by_fcapy(K_names, frames, \"imgs/lattice_visualization/fcapy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to construct a lattice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10\n",
    "timeout_secs = 5*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_order = sorted(frames, key=lambda K_name: pbench.get_context_stat(frames[K_name])['n_connections'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "680"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx_names_vals = frames_order\n",
    "lib_names_vals = ['concepts', 'fcapy']#, 'fcapsy']\n",
    "n_runs*len(ctx_names_vals)*len(lib_names_vals)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "stats_df = pbench.compute_stats(ctx_names_vals, lib_names_vals, n_runs, timeout_secs, frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = pd.read_csv('benchmark_stats_tmp.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9882352941176471\n"
     ]
    }
   ],
   "source": [
    "print(stats_df['is_computed'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df[stats_df['is_computed']].to_csv('benchmark_stats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(672, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_number</th>\n",
       "      <th>ctx_name</th>\n",
       "      <th>lib_name</th>\n",
       "      <th>is_computed</th>\n",
       "      <th>lattice_construction_time (secs)</th>\n",
       "      <th>intent_time (secs)</th>\n",
       "      <th>extent_time (secs)</th>\n",
       "      <th>timeout_seconds</th>\n",
       "      <th>n_objects</th>\n",
       "      <th>n_attributes</th>\n",
       "      <th>n_connections</th>\n",
       "      <th>density</th>\n",
       "      <th>is_random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>random_10_10_0.1</td>\n",
       "      <td>concepts</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>300.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>random_10_10_0.1</td>\n",
       "      <td>fcapy</td>\n",
       "      <td>True</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>300.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>animal_movement</td>\n",
       "      <td>concepts</td>\n",
       "      <td>True</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>300.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>animal_movement</td>\n",
       "      <td>fcapy</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>300.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>gewaesser</td>\n",
       "      <td>concepts</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>300.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run_number          ctx_name  lib_name  is_computed  \\\n",
       "0           0  random_10_10_0.1  concepts         True   \n",
       "1           0  random_10_10_0.1     fcapy         True   \n",
       "2           0   animal_movement  concepts         True   \n",
       "3           0   animal_movement     fcapy         True   \n",
       "4           0         gewaesser  concepts         True   \n",
       "\n",
       "   lattice_construction_time (secs)  intent_time (secs)  extent_time (secs)  \\\n",
       "0                          0.000682            0.000005            0.000005   \n",
       "1                          0.002102            0.000004            0.000006   \n",
       "2                          0.002020            0.000005            0.000004   \n",
       "3                          0.001931            0.000005            0.000007   \n",
       "4                          0.001259            0.000004            0.000004   \n",
       "\n",
       "   timeout_seconds  n_objects  n_attributes  n_connections  density  is_random  \n",
       "0            300.0       10.0          10.0            9.0    0.090       True  \n",
       "1            300.0       10.0          10.0            9.0    0.090       True  \n",
       "2            300.0       16.0           4.0           24.0    0.375      False  \n",
       "3            300.0       16.0           4.0           24.0    0.375      False  \n",
       "4            300.0        8.0           6.0           24.0    0.500      False  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_df = pd.read_csv('benchmark_stats.csv', index_col=0)\n",
    "print(stats_df.shape)\n",
    "stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = stats_df.fillna(timeout_secs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_stat_feats = ['n_objects', 'n_attributes', 'n_connections', 'density']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbench.save_context_stats(stats_df, context_stat_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbench.save_lattice_time_plot('imgs/lattice_construction_time/classic_contexts.png', context_stat_feats, stats_df[~stats_df['is_random']], timeout_secs)\n",
    "pbench.save_lattice_time_plot('imgs/lattice_construction_time/random_contexts.png', context_stat_feats, stats_df[stats_df['is_random']], timeout_secs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbench.save_extent_intent_time_plot('imgs/intent_extent_time/all_data.png', context_stat_feats, stats_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
